
# Lab Scenario Preview: Module 02: Explore the Content Safety Studio

## Lab overview

In this exercise, you will set up a single-service resource in Azure AI Content Safety Studio to evaluate and moderate text and image content, providing severity scores for various categories, ranging from safe to high.

## Lab objectives
In this lab, you will perform:
- Exploring the Content Safety Studio
- Associating a resource with the studio 
- Trying out text moderation in the Content Safety Studio
- Checking out the keys and endpoint

## Estimated timing: 30 minutes

## Solution Architecture

![](../media/Module1.1.png)

Once you understand the lab's content, you can start the Hands-on Lab by clicking the **Launch** button located in the top right corner. This will lead you to the lab environment and guide. You can also preview the full lab guide [here](https://experience.cloudlabs.ai/#/odl/3cba21af-4280-4ded-885f-cb9c5d11b664)
if you want to go through detailed guide prior to launching lab environment.  

