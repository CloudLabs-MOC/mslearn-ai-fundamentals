## Lesson 8: Explainable vs Non-Explainable AI Teacher Page
### Module Name: Explainable vs Non Explainable
#### Conceptual Model:
 
Conceptual Model for SREB Unit 3 Lesson 8: Explainable vs Non-Explainable

### Standards:

•	IAI.A2.1 Articulate the impact that computing devices and AI have in real-world settings (e.g., traffic lights, medical devices, facial recognition).

### Objectives:

•	Students will be able to define and differentiate explainable and non-explainable AI 

•	Students will be able to identify examples of both types of AI 

•	Students will explore and analyze how decision trees and neural networks function 

•	Students will evaluate the importance of transparency, trust, and regulatory compliance in AI decision-making 

•	Students will be able to justify the selection of explainable AI, non-explainable AI, or a hybrid approach based on specific use cases

### Storyline

In this lesson, students will explore the fundamental differences between explainable AI (XAI) and non-explainable AI (Black Box AI), identifying real-world examples and analyzing their strengths and weaknesses. Through hands-on activities, students will see examples of how each AI functions, helping them understand the importance of transparency, trust, accuracy, and regulatory compliance in AI systems. By the end of the lesson, students will evaluate the trade-offs of each approach and justify when one might be preferable over the other, particularly in fields like agriculture.

### Main Learning Goal
Students will be able to explain the key differences between explainable and non-explainable AI, assess their advantages and limitations, and determine their appropriate applications based on factors such as accuracy, transparency, and ethical considerations.

### Focus Question

What makes AI explainable or non-explainable, and how do these two approaches compare in terms of decision-making, trust, and real-world applications?  

### Tables
